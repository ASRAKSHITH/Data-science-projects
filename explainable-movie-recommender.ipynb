{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/asrakshithgowda007/explainable-movie-recommender?scriptVersionId=246502922\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Project: Explainable Movie Recommender using Generative AI\n\nThis notebook presents a project focused on building a movie recommendation system that goes beyond simply suggesting titles. The core goal is to provide **human-readable explanations** for *why* a particular movie is recommended.\n\n## The Problem\n\nTraditional recommendation systems, while effective, often function as \"black boxes.\" Users receive suggestions but lack insight into the underlying reasoning. This lack of transparency can reduce trust and limit user understanding of the recommendations provided.\n\n## The Solution\n\nThis project tackles the explainability problem by leveraging Generative AI capabilities. Instead of just matching items based on collaborative or content filtering alone, we use AI to understand movie content and user queries, find relevant movies, and then synthesize a natural language explanation for the recommendation.\n\n## Gen AI Capabilities Used\n\nThis project specifically utilizes the following Generative AI techniques:\n\n* **Embeddings:** Representing movie titles and descriptions as numerical vectors to capture semantic meaning and enable efficient similarity searching.\n* **Retrieval Augmented Generation (RAG):** Combining a retrieval step (finding relevant movies using embeddings) with a generation step (using an LLM to formulate the explanation based on the retrieved information).\n* **Prompting & Structured Output:** Crafting specific instructions (prompts) for the Large Language Model (LLM) to guide its response towards generating coherent and relevant explanations, potentially aiming for a desired structure in the output.","metadata":{}},{"cell_type":"markdown","source":"# Install key libraries","metadata":{}},{"cell_type":"code","source":"# Force upgrade/reinstall key libraries to ensure compatibility\n!pip install -q -- numpy scipy scikit-learn pandas\n!pip install -q -U google-generativeai\n\nprint(\"Libraries potentially updated. Please re-run the next cell (imports).\")\n# ===============================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:40.954529Z","iopub.execute_input":"2025-04-20T08:11:40.954868Z","iopub.status.idle":"2025-04-20T08:11:48.194328Z","shell.execute_reply.started":"2025-04-20T08:11:40.954845Z","shell.execute_reply":"2025-04-20T08:11:48.193293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Imports & API Key**","metadata":{}},{"cell_type":"code","source":"import google.generativeai as genai\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport json\nimport os\nimport kaggle_secrets \n\n# Configure API Key using the imported module\ntry:\n    \n    client = kaggle_secrets.UserSecretsClient()\n    GOOGLE_API_KEY = client.get_secret(\"GOOGLE_API_KEY\")\n    genai.configure(api_key=GOOGLE_API_KEY)\n    print(\"Google AI API Key configured successfully using Kaggle Secrets.\")\n\n    # Initialize the generative models\n    generation_model = genai.GenerativeModel('gemini-1.5-flash')\n    embedding_model = genai.GenerativeModel('models/embedding-001')\n    print(\"Generative models initialized.\")\n\nexcept kaggle_secrets.SecretNotFoundError:\n    print(\"ERROR: Kaggle Secret 'GOOGLE_API_KEY' not found.\")\n    print(\"Please ensure you have added your Google API key as a secret named 'GOOGLE_API_KEY' in your Kaggle notebook settings.\")\nexcept Exception as e:\n    print(f\"An unexpected error occurred during setup: {e}\")\n    # Potentially stop execution or handle the error appropriately\n    raise # Re-raise the exception to halt execution if setup fails critically\n\n# ===========================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:48.196132Z","iopub.execute_input":"2025-04-20T08:11:48.19642Z","iopub.status.idle":"2025-04-20T08:11:48.37607Z","shell.execute_reply.started":"2025-04-20T08:11:48.196397Z","shell.execute_reply":"2025-04-20T08:11:48.374996Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Movie Data Preparation# ","metadata":{}},{"cell_type":"markdown","source":"## Data Loading and Preparation\n\nThis section handles the initial loading and preparation of the movie dataset used for the recommender.\n\n* **Data Source:** For demonstration purposes in this notebook, a small sample of movie data (including Title, Genre, and Synopsis) is defined directly as a Python list of dictionaries.\n* **Real-world Scenario:** In a production system, this data would typically be loaded from external sources like CSV files, databases, or APIs.\n* **DataFrame Conversion:** The list of movie data is converted into a pandas DataFrame (`df_movies`) to facilitate data manipulation and integration with subsequent steps.\n* **Text for Embeddings:** A key step here is the creation of the `text_for_embedding` column. This column concatenates the 'title', 'genre', and 'synopsis' fields into a single string. This combined text provides the comprehensive input required by the embedding model to generate a meaningful vector representation for each movie.\n* **Verification:** The code prints the total number of movies loaded and displays the first few rows of the DataFrame to confirm successful loading and preparation.","metadata":{}},{"cell_type":"code","source":"# Simple movie dataset (Title, Genre, Synopsis)\n# In a real scenario, will load this from a CSV\nmovie_data = [\n    {\"movie_id\": 1, \"title\": \"Inception\", \"genre\": \"Sci-Fi, Action, Thriller\", \"synopsis\": \"A thief who steals corporate secrets through use of dream-sharing technology is given the inverse task of planting an idea into the mind of a C.E.O.\"},\n    {\"movie_id\": 2, \"title\": \"The Matrix\", \"genre\": \"Action, Sci-Fi\", \"synopsis\": \"A computer hacker learns from mysterious rebels about the true nature of his reality and his role in the war against its controllers.\"},\n    {\"movie_id\": 3, \"title\": \"Blade Runner 2049\", \"genre\": \"Sci-Fi, Thriller, Mystery\", \"synopsis\": \"Young Blade Runner K's discovery of a long-buried secret leads him to track down former Blade Runner Rick Deckard, who's been missing for thirty years.\"},\n    {\"movie_id\": 4, \"title\": \"Parasite\", \"genre\": \"Comedy, Drama, Thriller\", \"synopsis\": \"Greed and class discrimination threaten the newly formed symbiotic relationship between the wealthy Park family and the destitute Kim clan.\"},\n    {\"movie_id\": 5, \"title\": \"Spirited Away\", \"genre\": \"Animation, Adventure, Family\", \"synopsis\": \"During her family's move to the suburbs, a sullen 10-year-old girl wanders into a world ruled by gods, witches, and spirits, and where humans are changed into beasts.\"},\n    {\"movie_id\": 6, \"title\": \"Interstellar\", \"genre\": \"Sci-Fi, Drama, Adventure\", \"synopsis\": \"A team of explorers travel through a wormhole in space in an attempt to ensure humanity's survival.\"},\n    {\"movie_id\": 7, \"title\": \"Mad Max: Fury Road\", \"genre\": \"Action, Adventure, Sci-Fi\", \"synopsis\": \"In a post-apocalyptic wasteland, a woman rebels against a tyrannical ruler in search for her homeland with the help of a group of female prisoners, a psychotic worshiper, and a drifter named Max.\"},\n     {\"movie_id\": 8, \"title\": \"Arrival\", \"genre\": \"Sci-Fi, Drama, Mystery\", \"synopsis\": \"A linguist works with the military to communicate with alien lifeforms after twelve mysterious spacecraft appear around the world.\"},\n     {\"movie_id\": 9, \"title\": \"Eternal Sunshine of the Spotless Mind\", \"genre\": \"Drama, Romance, Sci-Fi\", \"synopsis\": \"When their relationship turns sour, a couple undergoes a medical procedure to have each other erased from their memories.\"},\n     {\"movie_id\": 10, \"title\": \"Pulp Fiction\", \"genre\": \"Crime, Drama\", \"synopsis\": \"The lives of two mob hitmen, a boxer, a gangster and his wife, and a pair of diner bandits intertwine in four tales of violence and redemption.\"}\n\n]\n\ndf_movies = pd.DataFrame(movie_data)\n\n# Combine text features for embedding\ndf_movies['text_for_embedding'] = df_movies['title'] + \". Genre: \" + df_movies['genre'] + \". Synopsis: \" + df_movies['synopsis']\n\nprint(f\"Loaded {len(df_movies)} movies.\")\nprint(df_movies.head()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:48.376909Z","iopub.execute_input":"2025-04-20T08:11:48.377169Z","iopub.status.idle":"2025-04-20T08:11:48.390284Z","shell.execute_reply.started":"2025-04-20T08:11:48.377151Z","shell.execute_reply":"2025-04-20T08:11:48.389464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Generate Movie Embeddings# ","metadata":{}},{"cell_type":"markdown","source":"## Creating Vector Representations (Embeddings)\n\nThis is a fundamental step where we transform the textual information about each movie into a numerical format that computers can easily process for similarity comparisons.\n\n* **Process:** The code iterates through the `text_for_embedding` created previously for each movie.\n* **Embedding Model:** It uses a pre-trained Generative AI embedding model (`models/text-embedding-004`) to generate a high-dimensional vector (the embedding) for each movie's text. The `RETRIEVAL_DOCUMENT` task type is specified, which is optimized for embedding documents that will be retrieved via search.\n* **Purpose:** These vectors capture the semantic meaning and context of the movie's description. Movies with similar themes, genres, or plot elements are expected to have vectors that are numerically closer to each other in the embedding space.\n* **Error Handling:** A mechanism is included to catch potential errors during the embedding generation for any movie. Movies that fail to generate an embedding are identified and removed from the dataset to ensure data integrity for the next steps.\n* **Output:** The generated embeddings are added as a new column (`embedding`) to the DataFrame. Finally, these embeddings are converted into a NumPy array (`movie_embedding_array`). This array structure is essential for efficient vector similarity search operations (like cosine similarity) later in the notebook.\n* **Efficiency Note:** For larger datasets, embedding generation is typically optimized by sending text in batches to the API rather than one by one, which is more efficient.","metadata":{}},{"cell_type":"code","source":"# Generate embeddings for each movie's text\n# Note: Batching requests is more efficient for large datasets\nmovie_embeddings = []\nprint(f\"Generating embeddings using model: models/embedding-004\") # Optional: Confirm model\n\n# Keep track of original number of movies\ninitial_movie_count = len(df_movies)\n\nfor idx, text in enumerate(df_movies['text_for_embedding']):\n    current_movie_title = df_movies.iloc[idx]['title'] # Get title for better logging\n    print(f\"Embedding movie {idx+1}/{initial_movie_count}: '{current_movie_title}'...\") \n    try:\n        # Call genai.embed_content directly, specifying the model name\n        response = genai.embed_content(\n            model=\"models/text-embedding-004\", \n            content=text,\n            task_type=\"RETRIEVAL_DOCUMENT\" #  RETRIEVAL_DOCUMENT for the items you'll search over\n        )\n        \n\n        movie_embeddings.append(response['embedding'])\n\n    except Exception as e:\n        # Provide more specific error info\n        print(f\"ERROR embedding text for movie '{current_movie_title}': {e}\")\n        print(f\"Failed text: {text}\")\n        movie_embeddings.append(None) # Handle potential errors by appending None\n\n# Add embeddings to the DataFrame\ndf_movies['embedding'] = movie_embeddings\n\n# Check how many failed before dropping\nfailed_count = df_movies['embedding'].isna().sum()\nif failed_count > 0:\n    print(f\"\\nWarning: Failed to generate embeddings for {failed_count} out of {initial_movie_count} movies.\")\n\ndf_movies.dropna(subset=['embedding'], inplace=True) # Remove rows where embedding failed\n\n# Convert list of embeddings into a NumPy array for similarity calculation\nif not df_movies.empty:\n    movie_embedding_array = np.array(df_movies['embedding'].tolist())\n    print(f\"\\nSuccessfully generated embeddings for {len(df_movies)} movies.\")\n    print(f\"Embedding array shape: {movie_embedding_array.shape}\") # Should be (num_movies, embedding_dim)\nelse:\n    movie_embedding_array = np.array([]) # Ensure it's an empty array if all failed\n    print(\"\\nERROR: No movie embeddings were successfully generated.\")\n    print(f\"Embedding array shape: {movie_embedding_array.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:48.391251Z","iopub.execute_input":"2025-04-20T08:11:48.39184Z","iopub.status.idle":"2025-04-20T08:11:50.693869Z","shell.execute_reply.started":"2025-04-20T08:11:48.39178Z","shell.execute_reply":"2025-04-20T08:11:50.692959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Recommendation Function (RAG + Generation)\n\n","metadata":{}},{"cell_type":"markdown","source":"## Building the Explainable Recommender: Retrieval Augmented Generation (RAG)\n\nThis section defines the core function `get_explainable_recommendation` which orchestrates the process of generating a movie recommendation and its accompanying explanation based on a user query. This function implements the **Retrieval Augmented Generation (RAG)** pattern:\n\n1.  **Retrieval (Query Embedding):** The user's input `user_query` is first converted into a vector embedding using the same embedding model (`models/text-embedding-004`), but with the `RETRIEVAL_QUERY` task type.\n2.  **Retrieval (Similarity Search):** The embedding of the user query is compared against the embeddings of all movie embeddings in our dataset (using cosine similarity). The function identifies the `top_n` movies whose embeddings are most similar to the query embedding. These are the initial candidates.\n3.  **Augmentation:** The detailed information (Title, Genre, Synopsis) for these top candidate movies is retrieved from the DataFrame. This information serves as the relevant \"context\" to augment the user's query for the next step.\n4.  **Generation (Prompting & LLM Call):** A detailed prompt is dynamically constructed. This prompt includes the original `user_query` and the structured information about the `candidate_movies`. The prompt explicitly instructs the Large Language Model (LLM) to:\n    * Select the *single best* recommendation from the provided candidates.\n    * Generate a *concise explanation* for the choice, referencing aspects relevant to the user's query or the movies' details.\n    * Format the output strictly as a JSON object with specified keys (`recommended_movie`, `explanation`).\n    The function then calls the `generation_model` with this comprehensive prompt.\n5.  **Output Parsing:** The text response received from the LLM is parsed. The code specifically looks for and extracts the JSON object containing the recommended movie title and its generated explanation, providing fallback mechanisms if the JSON format is unexpected.\n\nThe function returns the structured recommendation and explanation or an error message if the process could not be completed.","metadata":{}},{"cell_type":"code","source":"def get_explainable_recommendation(user_query, top_n=3):\n    \"\"\"\n    Gets a movie recommendation with explanation based on user query.\n\n    Args:\n        user_query (str): The user's request (e.g., \"a sci-fi movie like Blade Runner\").\n        top_n (int): Number of top similar movies to consider for the final recommendation.\n\n    Returns:\n        dict: A dictionary containing 'recommended_movie' and 'explanation', or an error message.\n    \"\"\"\n    if not user_query:\n        return {\"error\": \"Please provide a query.\"}\n    if movie_embedding_array.shape[0] == 0:\n         return {\"error\": \"No movie embeddings available.\"}\n\n\n    try:\n        # 1. Embed the user query (RAG - Retrieval Step 1)\n        query_embedding_response = genai.embed_content(\n            model=\"models/text-embedding-004\",\n            content=user_query,\n            task_type=\"RETRIEVAL_QUERY\" # Use RETRIEVAL_QUERY for the search query\n        )\n        query_embedding = np.array(query_embedding_response['embedding']).reshape(1, -1)\n\n        # 2. Find similar movies using Cosine Similarity (RAG - Retrieval Step 2)\n        similarities = cosine_similarity(query_embedding, movie_embedding_array)[0]\n\n        # Get indices of top N most similar movies\n        # We add 1 to top_n because the most similar might be the input movie itself if it's in the list\n        num_candidates = min(top_n + 1, len(similarities))\n        top_indices = np.argsort(similarities)[-num_candidates:][::-1] # Sort descending, get top indices\n\n        # 3. Prepare context for the LLM (RAG - Augmentation Step)\n        candidate_movies = []\n        print(f\"\\n--- Debug: Top {num_candidates} candidates based on similarity ---\")\n        for i in top_indices:\n            movie_info = df_movies.iloc[i]\n            # Optional: Exclude the exact movie mentioned in the query if found?\n            # For simplicity now, we don't exclude, LLM should handle it.\n            candidate_movies.append({\n                \"title\": movie_info[\"title\"],\n                \"genre\": movie_info[\"genre\"],\n                \"synopsis\": movie_info[\"synopsis\"]\n            })\n            print(f\"- {movie_info['title']} (Similarity: {similarities[i]:.4f})\")\n        print(\"------------------------------------------------------\")\n\n\n        # 4. Generate Recommendation and Explanation using LLM (Generation Step)\n        # Construct a detailed prompt\n        prompt = f\"\"\"\n        User query: \"{user_query}\"\n\n        Based on the user query, consider these potentially relevant movies:\n        {json.dumps(candidate_movies, indent=2)}\n\n        Your task:\n        1. Select the *single best* movie recommendation from the list above that matches the user query.\n        2. Provide a concise explanation (2-3 sentences) for *why* this movie is a good recommendation, connecting it to the user's query or the potential themes/genres implied by the query.\n        3. Format your response strictly as a JSON object with keys \"recommended_movie\" and \"explanation\".\n\n        Example Input Query: \"Suggest a dark sci-fi thriller\"\n        Example Output JSON:\n        {{\n          \"recommended_movie\": \"Blade Runner 2049\",\n          \"explanation\": \"Blade Runner 2049 fits your request for a dark sci-fi thriller. Like the original Blade Runner often associated with the genre, it features a moody atmosphere, complex philosophical themes, and a compelling mystery within its futuristic setting.\"\n        }}\n\n        Now, generate the JSON output for the user query: \"{user_query}\"\n        \"\"\"\n\n        # Call the Gemini model\n        response = generation_model.generate_content(prompt)\n\n        # 5. Parse the response\n        raw_response_text = response.text.strip()\n        print(f\"\\n--- Debug: Raw LLM Response ---\")\n        print(raw_response_text)\n        print(\"---------------------------------\")\n\n        # Attempt to clean and parse JSON (robustness for potential LLM formatting issues)\n        try:\n            # Find the start and end of the JSON object\n            json_start = raw_response_text.find('{')\n            json_end = raw_response_text.rfind('}') + 1\n            if json_start != -1 and json_end != -1:\n                json_string = raw_response_text[json_start:json_end]\n                parsed_output = json.loads(json_string)\n                if \"recommended_movie\" in parsed_output and \"explanation\" in parsed_output:\n                     return parsed_output\n                else:\n                    print(\"Warning: Parsed JSON missing required keys.\")\n                    # Fallback: Try to return the raw text if JSON parsing fails structurally\n                    return {\"recommendation_details\": raw_response_text}\n\n            else:\n                 print(\"Warning: Could not find JSON object in the response.\")\n                 return {\"recommendation_details\": raw_response_text} # Fallback\n\n        except json.JSONDecodeError as json_err:\n            print(f\"Error decoding JSON from LLM response: {json_err}\")\n            # Fallback: Return the raw text if JSON is invalid\n            return {\"recommendation_details\": raw_response_text}\n\n\n    except Exception as e:\n        print(f\"An error occurred during recommendation: {e}\")\n        import traceback\n        traceback.print_exc() # Print detailed traceback for debugging\n        return {\"error\": f\"An internal error occurred: {e}\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:50.695885Z","iopub.execute_input":"2025-04-20T08:11:50.696208Z","iopub.status.idle":"2025-04-20T08:11:50.707009Z","shell.execute_reply.started":"2025-04-20T08:11:50.69618Z","shell.execute_reply":"2025-04-20T08:11:50.706033Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# # 4. Testing the Explainable Recommender","metadata":{}},{"cell_type":"code","source":"# Test Case 1\nquery1 = \"Suggest a mind-bending sci-fi movie about dreams\"\nresult1 = get_explainable_recommendation(query1)\nprint(f\"\\nQuery: {query1}\")\nprint(f\"Result: {result1}\")\n\n# Test Case 2\nquery2 = \"I want an animated adventure movie from Japan\"\nresult2 = get_explainable_recommendation(query2)\nprint(f\"\\nQuery: {query2}\")\nprint(f\"Result: {result2}\")\n\n# Test Case 3\nquery3 = \"Looking for a thought-provoking sci-fi drama dealing with communication\"\nresult3 = get_explainable_recommendation(query3)\nprint(f\"\\nQuery: {query3}\")\nprint(f\"Result: {result3}\")\n\n# Test Case 4 (More vague)\nquery4 = \"Something action-packed in a desert\"\nresult4 = get_explainable_recommendation(query4)\nprint(f\"\\nQuery: {query4}\")\nprint(f\"Result: {result4}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T08:11:50.708182Z","iopub.execute_input":"2025-04-20T08:11:50.70852Z","iopub.status.idle":"2025-04-20T08:11:54.951557Z","shell.execute_reply.started":"2025-04-20T08:11:50.70849Z","shell.execute_reply":"2025-04-20T08:11:54.950683Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion\n\nThis project demonstrates the potential of leveraging Generative AI to build more transparent and explainable recommendation systems.\n\n## Results\n\nInitial testing on a few example movie queries showed that the system was able to retrieve relevant movies and generate plausible explanations based on the movie descriptions provided in the dataset. The quality of the explanations varied, sometimes being quite specific and other times more generic, depending on the movie and the query.\n\n## Limitations\n\nDespite the promising results, this prototype has several limitations:\n\n* **Small Dataset:** The recommendations and explanations are limited by the size and content of the dataset used. A larger, more diverse dataset would likely improve relevance.\n* **Embedding Model Limitations:** The performance is dependent on the quality and domain knowledge of the embedding model used. Generic models might struggle with nuanced movie concepts.\n* **LLM Hallucination/Genericity:** Large Language Models can sometimes generate factually incorrect (hallucinate) or overly generic explanations, especially if the context is limited or the prompt is not precise enough.\n* **Sensitivity to Prompt Phrasing:** The quality and focus of the generated explanation can be highly sensitive to the exact wording and structure of the prompt given to the LLM.\n\n## Future Work\n\nThere are several avenues for improving this explainable recommender:\n\n* **Larger and Richer Dataset:** Incorporating a dataset with more movies, richer metadata (genre, cast, director, plot summaries, tags), and potentially user interactions.\n* **Fine-tuning Embeddings:** Using or fine-tuning an embedding model specifically for the movie domain.\n* **Incorporating User Profiles:** Including user history and preferences to personalize recommendations beyond just the current query.\n* **Adding Conversational Abilities:** Making the system more agent-like, allowing users to refine recommendations through dialogue.\n* **Function Calling:** Utilizing LLM function calling to potentially retrieve external data like movie ratings or reviews to enrich explanations.\n* **Stricter Gen AI Evaluation:** Developing more robust methods to evaluate the quality, relevance, and factual accuracy of the generated explanations.\n\n## Final Thoughts\n\nProviding explanations for recommendations is crucial for building user trust and improving the overall user experience. This project serves as a foundation for exploring how Generative AI, through techniques like embeddings, RAG, and prompting, can unlock this valuable explainability layer in recommendation systems.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}